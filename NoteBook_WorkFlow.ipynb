{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-05T09:04:02.626843Z",
     "start_time": "2025-07-05T09:03:53.946801Z"
    }
   },
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "from sympy.physics.units import frequency\n",
    "from torch.nn.functional import embedding\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:11:52.015548Z",
     "start_time": "2025-07-05T09:11:52.010547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dir=Path(\"files\")\n",
    "dir.mkdir(parents=True, exist_ok=True)\n"
   ],
   "id": "9eef38204a3e94b8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T14:37:14.553904Z",
     "start_time": "2025-07-04T14:37:13.529004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "req=requests.get(\"https://raw.githubusercontent.com/neychev/\"\n",
    "     \"small_DL_repo/master/datasets/Multi30k/training.tar.gz\")\n",
    "with open(\"files/training.tar.gz\", \"wb\") as f:\n",
    "    f.write(req.content)\n"
   ],
   "id": "9575410549dc45e4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Extracting the tar file",
   "id": "622b4e7006004321"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T19:51:36.016616Z",
     "start_time": "2025-07-04T19:51:35.969454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tarfile\n",
    "#To read TarFile\n",
    "train=tarfile.open('files/training.tar.gz')    #C\n",
    "train.extractall('files',filter=\"fully_trusted\")    #D\n",
    "train.close()"
   ],
   "id": "696c0caafabbcf7c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:11:55.150663Z",
     "start_time": "2025-07-05T09:11:55.127922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"./train.de\", \"rb\") as f:\n",
    "    trainde=f.readlines()"
   ],
   "id": "b9d53c3aacf9c3ef",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:11:55.992274Z",
     "start_time": "2025-07-05T09:11:55.971139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"./train.en\", \"rb\") as f:\n",
    "    trainen=f.readlines()"
   ],
   "id": "9c05c33aab30d2cd",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#Converting the read(decompressed files into arrays of phrases seperated by Lines)",
   "id": "ff1d6c6358454b7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:11:57.846486Z",
     "start_time": "2025-07-05T09:11:57.831158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "trainde=[i.decode(\"utf-8\").strip() for i in trainde]"
   ],
   "id": "39ec14073a5ef3cb",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:11:58.453876Z",
     "start_time": "2025-07-05T09:11:58.444839Z"
    }
   },
   "cell_type": "code",
   "source": "trainen=[i.decode(\"utf-8\").strip() for i in trainen]",
   "id": "12bea790aea6da9c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:11:59.221914Z",
     "start_time": "2025-07-05T09:11:59.215001Z"
    }
   },
   "cell_type": "code",
   "source": "trainen[2900]",
   "id": "dd66e1501959bd4d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A person looks out of the window on the A bus.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "SPACY:Introduction",
   "id": "81588cbcec378d9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:12:06.254769Z",
     "start_time": "2025-07-05T09:12:01.889338Z"
    }
   },
   "cell_type": "code",
   "source": "import spacy,os\n",
   "id": "4127a7f051a6eb13",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Setup for spacy\n",
    "\n",
    "En->English, de->German Tokenizer"
   ],
   "id": "ba4c8cded27c237c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:12:11.662436Z",
     "start_time": "2025-07-05T09:12:10.512695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "de_token=spacy.load('de_core_news_sm')\n",
    "\n"
   ],
   "id": "613fd6485a7c14ac",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:12:13.199599Z",
     "start_time": "2025-07-05T09:12:12.626843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "en_token=spacy.load('en_core_web_sm')\n",
    "\n"
   ],
   "id": "95e189cae9d25333",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:12:23.106555Z",
     "start_time": "2025-07-05T09:12:23.099847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_single_de=[tok.text for tok in\n",
    "              de_token.tokenizer(trainde[0])]\n",
    "token_single_en=[tok.text for tok in\n",
    "              en_token.tokenizer(trainen[0])]\n",
    "print(token_single_en)\n",
    "print(token_single_de)"
   ],
   "id": "b7e4fd37a9830496",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Two', 'young', ',', 'White', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n",
      "['Zwei', 'junge', 'weiße', 'Männer', 'sind', 'im', 'Freien', 'in', 'der', 'Nähe', 'vieler', 'Büsche', '.']\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T19:52:21.756545Z",
     "start_time": "2025-07-04T19:52:21.751585Z"
    }
   },
   "cell_type": "code",
   "source": "trainen[0]",
   "id": "70fc746cc9f91094",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Two young, White males are outside near many bushes.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Building A dictionary for the above Token; Each Unique word is reprensted by a unique indecx in the dictionary",
   "id": "c3dcdd8afa06911a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:12:26.443917Z",
     "start_time": "2025-07-05T09:12:26.440068Z"
    }
   },
   "cell_type": "code",
   "source": "from collections import Counter\n",
   "id": "e82fa80c0238b8a0",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:12:31.611715Z",
     "start_time": "2025-07-05T09:12:27.636733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_full_en=[[\"BOS\"]+[tok.text for tok in en_token.tokenizer(x)]+[\"EOS\"] for x in trainen ]\n",
    "token_full_de=[[\"BOS\"]+[tok.text for tok in en_token.tokenizer(x)]+[\"EOS\"] for x in trainde ]"
   ],
   "id": "d9b5e9eb453e74eb",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "English Dict",
   "id": "2f309a099ecd6fce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:12:33.249373Z",
     "start_time": "2025-07-05T09:12:33.127460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "en_word_count=Counter()\n",
    "for sent in token_full_en:\n",
    "    for word in sent:\n",
    "        en_word_count[word]+=1\n",
    "PAD=0\n",
    "UNK=1\n",
    "frequency_en=en_word_count.most_common(50000)\n",
    "en_total_word=len(frequency_en)+2\n",
    "#Counter-> Returns the word Itself and the count\n",
    "\n",
    "en_word_dict={w[0]:idx+2 for idx,w in enumerate(frequency_en)}\n",
    "en_word_dict[\"PAD\"]=PAD\n",
    "en_word_dict[\"UNK\"]=UNK\n",
    "en_idx_dict={v:k for k,v in en_word_dict.items()}\n",
    "\n"
   ],
   "id": "28b070c55e1e5aba",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:12:36.025279Z",
     "start_time": "2025-07-05T09:12:36.021085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "endix=[en_word_dict.get(i,UNK) for i in token_single_en]\n",
    "print(endix)"
   ],
   "id": "a4622b14357c0e2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 25, 15, 1165, 804, 17, 57, 84, 334, 1329, 5]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:12:37.277116Z",
     "start_time": "2025-07-05T09:12:37.273445Z"
    }
   },
   "cell_type": "code",
   "source": "print([en_idx_dict.get(i,\"UNK\") for i in endix])",
   "id": "f32866a6fd93a472",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Two', 'young', ',', 'White', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "German Dict",
   "id": "fa929fb265cf6723"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:12:41.380805Z",
     "start_time": "2025-07-05T09:12:41.250648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "de_word_count=Counter()\n",
    "for sent in token_full_de:\n",
    "    for word in sent:\n",
    "        de_word_count[word]+=1\n",
    "de_frequency=de_word_count.most_common(50000)\n",
    "de_total_word=len(de_frequency)+2\n",
    "de_word_dict={w[0]:idx+2 for idx,w in enumerate(de_frequency)}\n",
    "de_word_dict[\"PAD\"]=PAD\n",
    "de_word_dict[\"UNK\"]=UNK\n",
    "de_idx_dict={v:k for k,v in de_word_dict.items()}"
   ],
   "id": "2e6037203293cf1",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:12:44.232497Z",
     "start_time": "2025-07-05T09:12:44.228497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "de_idx=[de_word_dict.get(i,UNK) for i in token_single_de]\n",
    "print(de_idx)"
   ],
   "id": "ad66361dd22ea3b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 87, 221, 33, 89, 1, 97, 7, 16, 117, 5538, 3208, 4]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:12:45.602993Z",
     "start_time": "2025-07-05T09:12:45.598905Z"
    }
   },
   "cell_type": "code",
   "source": "print([en_word_dict.get(i,\"Unknown\") for i in token_full_en[1]])",
   "id": "45731db8f6d985cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 164, 36, 7, 335, 286, 17, 1208, 2, 753, 3933, 2710, 5, 4]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:12:46.531037Z",
     "start_time": "2025-07-05T09:12:46.526552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a=[en_word_dict.get(i,\"Unknown\") for i in token_full_en[1]]\n",
    "print([en_idx_dict.get(i,\"Unknown\") for i in a])"
   ],
   "id": "fdae7f3876d98710",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BOS', 'Several', 'men', 'in', 'hard', 'hats', 'are', 'operating', 'a', 'giant', 'pulley', 'system', '.', 'EOS']\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:13:10.905308Z",
     "start_time": "2025-07-05T09:13:10.901502Z"
    }
   },
   "cell_type": "code",
   "source": "print([de_idx_dict.get(i,UNK) for i in de_idx])",
   "id": "c6a28cebd46a468b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Zwei', 'junge', 'weiße', 'Männer', 'sind', 'UNK', 'Freien', 'in', 'der', 'Nähe', 'vieler', 'Büsche', '.']\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Word dictionary\n",
    "\n",
    "\n",
    "Key,Val=word,id\n",
    "\n",
    "\n",
    "Index Dictionary\n",
    "\n",
    "\n",
    "Key,val->Index,word"
   ],
   "id": "52c8e4ba19bfc298"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:13:12.826132Z",
     "start_time": "2025-07-05T09:13:12.685882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Adding Padding So that the dictionary is of Equal Length\n",
    "\n",
    "\n",
    "out_en_ids=[[en_word_dict.get(w,UNK) for w in s]\n",
    "            for s in token_full_en]\n",
    "out_de_ids=[[de_word_dict.get(w,UNK) for w in s]\n",
    "            for s in token_full_de]\n"
   ],
   "id": "19e92e78bf686d6f",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:13:15.200541Z",
     "start_time": "2025-07-05T09:13:15.182160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Sorts the lists basesd on the lomngest german phrase : and Aligns it with the English Phrases for a Sample -Label Pairing\n",
    "sorted_ids=sorted(range(len(out_de_ids)),\n",
    "                  key=lambda x:len(out_de_ids[x]))\n",
    "\n",
    "out_de_ids=[out_de_ids[x] for x in sorted_ids]\n",
    "out_en_ids=[out_en_ids[x] for x in sorted_ids]"
   ],
   "id": "d7ef6b1c8b652c8c",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Making Training Batches",
   "id": "33918cd1898d1aa4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:13:17.979638Z",
     "start_time": "2025-07-05T09:13:17.972372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "batch_size=128\n",
    "idx_list=np.arange(0,len(token_full_de),batch_size)\n",
    "np.random.shuffle(idx_list)\n",
    "batch_indexs=[]\n",
    "for idx in idx_list:\n",
    "    batch_indexs.append(np.arange(idx,min(len(token_full_de),idx+batch_size)))\n",
    "\n",
    "#Similar to dataloader ,just more formal approach"
   ],
   "id": "304a4c20740a1c4",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:13:21.398983Z",
     "start_time": "2025-07-05T09:13:21.394349Z"
    }
   },
   "cell_type": "code",
   "source": "len(out_en_ids)",
   "id": "d106519fefded824",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29001"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:19:17.466504Z",
     "start_time": "2025-07-05T09:19:17.462273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def seq_padding(X, padding=PAD):\n",
    "    L = [len(x) for x in X]\n",
    "    ML = max(L)\n",
    "    padded_seq = np.array([np.concatenate([x,\n",
    "                   [padding] * (ML - len(x))])\n",
    "        if len(x) < ML else x for x in X])\n",
    "    return padded_seq"
   ],
   "id": "6e2af6490796ed74",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:13:24.778267Z",
     "start_time": "2025-07-05T09:13:24.774656Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "753a4a9671e34961",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:13:25.579526Z",
     "start_time": "2025-07-05T09:13:25.575803Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")",
   "id": "2bde5f6c56309b63",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:13:26.415705Z",
     "start_time": "2025-07-05T09:13:26.411104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "device"
   ],
   "id": "cd24c9ec070805c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Self-Attention MASKING",
   "id": "1f1a163a80134187"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:21:19.874711Z",
     "start_time": "2025-07-05T09:21:19.869847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#During Training Decoder is autoregressive via masking\"\n",
    "def subsequent_mask(size):\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape),\n",
    "                              k=1).astype('uint8')\n",
    "    output = torch.from_numpy(subsequent_mask) == 0\n",
    "    return output\n",
    "\n",
    "def make_std_mask(tgt, pad):\n",
    "    tgt_mask=(tgt != pad).unsqueeze(-2)\n",
    "    output=tgt_mask & subsequent_mask(\\\n",
    "        tgt.size(-1)).type_as(tgt_mask.data)\n",
    "    return output\n",
    "\n",
    "class Batch:\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        src = torch.from_numpy(src).to(device).long()\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if trg is not None:\n",
    "            trg = torch.from_numpy(trg).to(device).long()\n",
    "            #Targ is the decoder input during training\n",
    "            self.trg = trg[:, :-1]\n",
    "\n",
    "            #Targ_y is the decoder expected output->during testing\n",
    "            #Non Auto Regressive\n",
    "            self.trg_y = trg[:, 1:]\n",
    "\n",
    "            self.trg_mask = make_std_mask(self.trg, pad)\n",
    "            #ntokens counts the number of real tokens\n",
    "            self.ntokens = (self.trg_y != pad).data.sum()\n"
   ],
   "id": "3b27aadc87493f6d",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:14:25.890201Z",
     "start_time": "2025-07-05T09:14:25.169614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "batches=[]\n",
    "for b in batch_indexs:\n",
    "\n",
    "    batch_en=[out_en_ids[x] for x in b]\n",
    "    batch_de=[out_de_ids[x] for x in b]\n",
    "\n",
    "    batch_en=seq_padding(batch_en)\n",
    "    batch_de=seq_padding(batch_de)\n",
    "    batches.append(Batch(batch_de,batch_en))"
   ],
   "id": "27553b0b0368a1ae",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T17:06:40.528336Z",
     "start_time": "2025-07-03T17:06:40.523893Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5cdaa40d4f7fd1a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 12])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:24:25.180478Z",
     "start_time": "2025-07-05T09:24:25.176811Z"
    }
   },
   "cell_type": "code",
   "source": "print([en_idx_dict.get(i,UNK) for i in out_en_ids[100]])",
   "id": "be0d0a9b694f19ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BOS', 'Looks', 'like', 'students', 'are', 'in', 'a', 'laboratory', '.', 'EOS']\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:24:27.866285Z",
     "start_time": "2025-07-05T09:24:27.862444Z"
    }
   },
   "cell_type": "code",
   "source": "print([de_idx_dict.get(i,UNK) for i in out_de_ids[100]])",
   "id": "518ea33d45575c48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BOS', 'Schüler', 'in', 'einem', 'Labor', '.', 'EOS']\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Word Embedding",
   "id": "cc2a7693e75fde4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:24:30.668613Z",
     "start_time": "2025-07-05T09:24:30.664886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(de_word_dict)),print(len(en_word_dict))\n",
    "src_vocab=len(de_word_dict)\n",
    "trg_vocab=len(en_word_dict)\n",
    "#UniqueWords int german and English Phrases"
   ],
   "id": "141ec354f74efc8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18544\n",
      "10837\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:24:36.700168Z",
     "start_time": "2025-07-05T09:24:36.696422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "from torch import nn\n",
    "d_model=256"
   ],
   "id": "e04ef03220925385",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:24:56.114780Z",
     "start_time": "2025-07-05T09:24:56.110746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self,d_model,vocab):\n",
    "        super().__init__()\n",
    "        self.lut=nn.Embedding(vocab,d_model)\n",
    "        self.d_model=d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        out=self.lut(x)*math.sqrt(self.d_model)\n",
    "        return out\n"
   ],
   "id": "608704a972620da3",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T14:40:03.709182Z",
     "start_time": "2025-07-04T14:40:03.704424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Cool Python Facts\n",
    "[1,2]*4"
   ],
   "id": "4ed613137abd645d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 2, 1, 2, 1, 2]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Final input to transformer\n",
    "input_representation = embedding × √d_model + positional_encoding"
   ],
   "id": "cfa5915753ff6038"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Positonal Encoding",
   "id": "db417ec1e27adace"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:25:08.911175Z",
     "start_time": "2025-07-05T09:25:08.905086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#INPUT to Positional Encoding will be the output of Embeddings of the sentences\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model, device=device)\n",
    "        position = torch.arange(0., max_len,\n",
    "                                device=device).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(\n",
    "            0., d_model, 2, device=device)\n",
    "            * -(math.log(10000.0) / d_model))\n",
    "        pe_pos = torch.mul(position, div_term)\n",
    "        pe[:, 0::2] = torch.sin(pe_pos)\n",
    "        pe[:, 1::2] = torch.cos(pe_pos)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)].requires_grad_(False)\n",
    "        out = self.dropout(x)\n",
    "        return out"
   ],
   "id": "320028cb54d25606",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T16:47:05.880855Z",
     "start_time": "2025-07-03T16:47:05.809915Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "599d8e9f25279cd3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.],\n",
       "        [  1.],\n",
       "        [  2.],\n",
       "        [  3.],\n",
       "        [  4.],\n",
       "        [  5.],\n",
       "        [  6.],\n",
       "        [  7.],\n",
       "        [  8.],\n",
       "        [  9.],\n",
       "        [ 10.],\n",
       "        [ 11.],\n",
       "        [ 12.],\n",
       "        [ 13.],\n",
       "        [ 14.],\n",
       "        [ 15.],\n",
       "        [ 16.],\n",
       "        [ 17.],\n",
       "        [ 18.],\n",
       "        [ 19.],\n",
       "        [ 20.],\n",
       "        [ 21.],\n",
       "        [ 22.],\n",
       "        [ 23.],\n",
       "        [ 24.],\n",
       "        [ 25.],\n",
       "        [ 26.],\n",
       "        [ 27.],\n",
       "        [ 28.],\n",
       "        [ 29.],\n",
       "        [ 30.],\n",
       "        [ 31.],\n",
       "        [ 32.],\n",
       "        [ 33.],\n",
       "        [ 34.],\n",
       "        [ 35.],\n",
       "        [ 36.],\n",
       "        [ 37.],\n",
       "        [ 38.],\n",
       "        [ 39.],\n",
       "        [ 40.],\n",
       "        [ 41.],\n",
       "        [ 42.],\n",
       "        [ 43.],\n",
       "        [ 44.],\n",
       "        [ 45.],\n",
       "        [ 46.],\n",
       "        [ 47.],\n",
       "        [ 48.],\n",
       "        [ 49.],\n",
       "        [ 50.],\n",
       "        [ 51.],\n",
       "        [ 52.],\n",
       "        [ 53.],\n",
       "        [ 54.],\n",
       "        [ 55.],\n",
       "        [ 56.],\n",
       "        [ 57.],\n",
       "        [ 58.],\n",
       "        [ 59.],\n",
       "        [ 60.],\n",
       "        [ 61.],\n",
       "        [ 62.],\n",
       "        [ 63.],\n",
       "        [ 64.],\n",
       "        [ 65.],\n",
       "        [ 66.],\n",
       "        [ 67.],\n",
       "        [ 68.],\n",
       "        [ 69.],\n",
       "        [ 70.],\n",
       "        [ 71.],\n",
       "        [ 72.],\n",
       "        [ 73.],\n",
       "        [ 74.],\n",
       "        [ 75.],\n",
       "        [ 76.],\n",
       "        [ 77.],\n",
       "        [ 78.],\n",
       "        [ 79.],\n",
       "        [ 80.],\n",
       "        [ 81.],\n",
       "        [ 82.],\n",
       "        [ 83.],\n",
       "        [ 84.],\n",
       "        [ 85.],\n",
       "        [ 86.],\n",
       "        [ 87.],\n",
       "        [ 88.],\n",
       "        [ 89.],\n",
       "        [ 90.],\n",
       "        [ 91.],\n",
       "        [ 92.],\n",
       "        [ 93.],\n",
       "        [ 94.],\n",
       "        [ 95.],\n",
       "        [ 96.],\n",
       "        [ 97.],\n",
       "        [ 98.],\n",
       "        [ 99.],\n",
       "        [100.],\n",
       "        [101.],\n",
       "        [102.],\n",
       "        [103.],\n",
       "        [104.],\n",
       "        [105.],\n",
       "        [106.],\n",
       "        [107.],\n",
       "        [108.],\n",
       "        [109.],\n",
       "        [110.],\n",
       "        [111.],\n",
       "        [112.],\n",
       "        [113.],\n",
       "        [114.],\n",
       "        [115.],\n",
       "        [116.],\n",
       "        [117.],\n",
       "        [118.],\n",
       "        [119.],\n",
       "        [120.],\n",
       "        [121.],\n",
       "        [122.],\n",
       "        [123.],\n",
       "        [124.],\n",
       "        [125.],\n",
       "        [126.],\n",
       "        [127.],\n",
       "        [128.],\n",
       "        [129.],\n",
       "        [130.],\n",
       "        [131.],\n",
       "        [132.],\n",
       "        [133.],\n",
       "        [134.],\n",
       "        [135.],\n",
       "        [136.],\n",
       "        [137.],\n",
       "        [138.],\n",
       "        [139.],\n",
       "        [140.],\n",
       "        [141.],\n",
       "        [142.],\n",
       "        [143.],\n",
       "        [144.],\n",
       "        [145.],\n",
       "        [146.],\n",
       "        [147.],\n",
       "        [148.],\n",
       "        [149.],\n",
       "        [150.],\n",
       "        [151.],\n",
       "        [152.],\n",
       "        [153.],\n",
       "        [154.],\n",
       "        [155.],\n",
       "        [156.],\n",
       "        [157.],\n",
       "        [158.],\n",
       "        [159.],\n",
       "        [160.],\n",
       "        [161.],\n",
       "        [162.],\n",
       "        [163.],\n",
       "        [164.],\n",
       "        [165.],\n",
       "        [166.],\n",
       "        [167.],\n",
       "        [168.],\n",
       "        [169.],\n",
       "        [170.],\n",
       "        [171.],\n",
       "        [172.],\n",
       "        [173.],\n",
       "        [174.],\n",
       "        [175.],\n",
       "        [176.],\n",
       "        [177.],\n",
       "        [178.],\n",
       "        [179.],\n",
       "        [180.],\n",
       "        [181.],\n",
       "        [182.],\n",
       "        [183.],\n",
       "        [184.],\n",
       "        [185.],\n",
       "        [186.],\n",
       "        [187.],\n",
       "        [188.],\n",
       "        [189.],\n",
       "        [190.],\n",
       "        [191.],\n",
       "        [192.],\n",
       "        [193.],\n",
       "        [194.],\n",
       "        [195.],\n",
       "        [196.],\n",
       "        [197.],\n",
       "        [198.],\n",
       "        [199.],\n",
       "        [200.],\n",
       "        [201.],\n",
       "        [202.],\n",
       "        [203.],\n",
       "        [204.],\n",
       "        [205.],\n",
       "        [206.],\n",
       "        [207.],\n",
       "        [208.],\n",
       "        [209.],\n",
       "        [210.],\n",
       "        [211.],\n",
       "        [212.],\n",
       "        [213.],\n",
       "        [214.],\n",
       "        [215.],\n",
       "        [216.],\n",
       "        [217.],\n",
       "        [218.],\n",
       "        [219.],\n",
       "        [220.],\n",
       "        [221.],\n",
       "        [222.],\n",
       "        [223.],\n",
       "        [224.],\n",
       "        [225.],\n",
       "        [226.],\n",
       "        [227.],\n",
       "        [228.],\n",
       "        [229.],\n",
       "        [230.],\n",
       "        [231.],\n",
       "        [232.],\n",
       "        [233.],\n",
       "        [234.],\n",
       "        [235.],\n",
       "        [236.],\n",
       "        [237.],\n",
       "        [238.],\n",
       "        [239.],\n",
       "        [240.],\n",
       "        [241.],\n",
       "        [242.],\n",
       "        [243.],\n",
       "        [244.],\n",
       "        [245.],\n",
       "        [246.],\n",
       "        [247.],\n",
       "        [248.],\n",
       "        [249.],\n",
       "        [250.],\n",
       "        [251.],\n",
       "        [252.],\n",
       "        [253.],\n",
       "        [254.],\n",
       "        [255.],\n",
       "        [256.],\n",
       "        [257.],\n",
       "        [258.],\n",
       "        [259.],\n",
       "        [260.],\n",
       "        [261.],\n",
       "        [262.],\n",
       "        [263.],\n",
       "        [264.],\n",
       "        [265.],\n",
       "        [266.],\n",
       "        [267.],\n",
       "        [268.],\n",
       "        [269.],\n",
       "        [270.],\n",
       "        [271.],\n",
       "        [272.],\n",
       "        [273.],\n",
       "        [274.],\n",
       "        [275.],\n",
       "        [276.],\n",
       "        [277.],\n",
       "        [278.],\n",
       "        [279.],\n",
       "        [280.],\n",
       "        [281.],\n",
       "        [282.],\n",
       "        [283.],\n",
       "        [284.],\n",
       "        [285.],\n",
       "        [286.],\n",
       "        [287.],\n",
       "        [288.],\n",
       "        [289.],\n",
       "        [290.],\n",
       "        [291.],\n",
       "        [292.],\n",
       "        [293.],\n",
       "        [294.],\n",
       "        [295.],\n",
       "        [296.],\n",
       "        [297.],\n",
       "        [298.],\n",
       "        [299.],\n",
       "        [300.],\n",
       "        [301.],\n",
       "        [302.],\n",
       "        [303.],\n",
       "        [304.],\n",
       "        [305.],\n",
       "        [306.],\n",
       "        [307.],\n",
       "        [308.],\n",
       "        [309.],\n",
       "        [310.],\n",
       "        [311.],\n",
       "        [312.],\n",
       "        [313.],\n",
       "        [314.],\n",
       "        [315.],\n",
       "        [316.],\n",
       "        [317.],\n",
       "        [318.],\n",
       "        [319.],\n",
       "        [320.],\n",
       "        [321.],\n",
       "        [322.],\n",
       "        [323.],\n",
       "        [324.],\n",
       "        [325.],\n",
       "        [326.],\n",
       "        [327.],\n",
       "        [328.],\n",
       "        [329.],\n",
       "        [330.],\n",
       "        [331.],\n",
       "        [332.],\n",
       "        [333.],\n",
       "        [334.],\n",
       "        [335.],\n",
       "        [336.],\n",
       "        [337.],\n",
       "        [338.],\n",
       "        [339.],\n",
       "        [340.],\n",
       "        [341.],\n",
       "        [342.],\n",
       "        [343.],\n",
       "        [344.],\n",
       "        [345.],\n",
       "        [346.],\n",
       "        [347.],\n",
       "        [348.],\n",
       "        [349.],\n",
       "        [350.],\n",
       "        [351.],\n",
       "        [352.],\n",
       "        [353.],\n",
       "        [354.],\n",
       "        [355.],\n",
       "        [356.],\n",
       "        [357.],\n",
       "        [358.],\n",
       "        [359.],\n",
       "        [360.],\n",
       "        [361.],\n",
       "        [362.],\n",
       "        [363.],\n",
       "        [364.],\n",
       "        [365.],\n",
       "        [366.],\n",
       "        [367.],\n",
       "        [368.],\n",
       "        [369.],\n",
       "        [370.],\n",
       "        [371.],\n",
       "        [372.],\n",
       "        [373.],\n",
       "        [374.],\n",
       "        [375.],\n",
       "        [376.],\n",
       "        [377.],\n",
       "        [378.],\n",
       "        [379.],\n",
       "        [380.],\n",
       "        [381.],\n",
       "        [382.],\n",
       "        [383.],\n",
       "        [384.],\n",
       "        [385.],\n",
       "        [386.],\n",
       "        [387.],\n",
       "        [388.],\n",
       "        [389.],\n",
       "        [390.],\n",
       "        [391.],\n",
       "        [392.],\n",
       "        [393.],\n",
       "        [394.],\n",
       "        [395.],\n",
       "        [396.],\n",
       "        [397.],\n",
       "        [398.],\n",
       "        [399.],\n",
       "        [400.],\n",
       "        [401.],\n",
       "        [402.],\n",
       "        [403.],\n",
       "        [404.],\n",
       "        [405.],\n",
       "        [406.],\n",
       "        [407.],\n",
       "        [408.],\n",
       "        [409.],\n",
       "        [410.],\n",
       "        [411.],\n",
       "        [412.],\n",
       "        [413.],\n",
       "        [414.],\n",
       "        [415.],\n",
       "        [416.],\n",
       "        [417.],\n",
       "        [418.],\n",
       "        [419.],\n",
       "        [420.],\n",
       "        [421.],\n",
       "        [422.],\n",
       "        [423.],\n",
       "        [424.],\n",
       "        [425.],\n",
       "        [426.],\n",
       "        [427.],\n",
       "        [428.],\n",
       "        [429.],\n",
       "        [430.],\n",
       "        [431.],\n",
       "        [432.],\n",
       "        [433.],\n",
       "        [434.],\n",
       "        [435.],\n",
       "        [436.],\n",
       "        [437.],\n",
       "        [438.],\n",
       "        [439.],\n",
       "        [440.],\n",
       "        [441.],\n",
       "        [442.],\n",
       "        [443.],\n",
       "        [444.],\n",
       "        [445.],\n",
       "        [446.],\n",
       "        [447.],\n",
       "        [448.],\n",
       "        [449.],\n",
       "        [450.],\n",
       "        [451.],\n",
       "        [452.],\n",
       "        [453.],\n",
       "        [454.],\n",
       "        [455.],\n",
       "        [456.],\n",
       "        [457.],\n",
       "        [458.],\n",
       "        [459.],\n",
       "        [460.],\n",
       "        [461.],\n",
       "        [462.],\n",
       "        [463.],\n",
       "        [464.],\n",
       "        [465.],\n",
       "        [466.],\n",
       "        [467.],\n",
       "        [468.],\n",
       "        [469.],\n",
       "        [470.],\n",
       "        [471.],\n",
       "        [472.],\n",
       "        [473.],\n",
       "        [474.],\n",
       "        [475.],\n",
       "        [476.],\n",
       "        [477.],\n",
       "        [478.],\n",
       "        [479.],\n",
       "        [480.],\n",
       "        [481.],\n",
       "        [482.],\n",
       "        [483.],\n",
       "        [484.],\n",
       "        [485.],\n",
       "        [486.],\n",
       "        [487.],\n",
       "        [488.],\n",
       "        [489.],\n",
       "        [490.],\n",
       "        [491.],\n",
       "        [492.],\n",
       "        [493.],\n",
       "        [494.],\n",
       "        [495.],\n",
       "        [496.],\n",
       "        [497.],\n",
       "        [498.],\n",
       "        [499.]], device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Multi Head Attention & Feed Forward Network",
   "id": "777d1217017cce4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:25:11.815094Z",
     "start_time": "2025-07-05T09:25:11.812244Z"
    }
   },
   "cell_type": "code",
   "source": "from copy import deepcopy",
   "id": "c9d6fc0f58c20b64",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:44:31.998814Z",
     "start_time": "2025-07-05T09:44:31.990601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query,\n",
    "              key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = nn.functional.softmax(scores, dim=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % h == 0\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = nn.ModuleList([deepcopy(\n",
    "            nn.Linear(d_model, d_model)) for i in range(4)])\n",
    "        self.attn =None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        query, key, value = [l(x).view(nbatches, -1, self.h,\n",
    "           self.d_k).transpose(1, 2)\n",
    "        #The transpose is done to enable Matrix Multiplication->mentioned in Hugging Face\n",
    "\n",
    "         for l, x in zip(self.linears, (query, key, value))]\n",
    "        x, self.attn = attention(\n",
    "            query, key, value, mask=mask, dropout=self.dropout)\n",
    "        x = x.transpose(1, 2).contiguous().view(\n",
    "            nbatches, -1, self.h * self.d_k)\n",
    "        output = self.linears[-1](x)\n",
    "        return output\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.w_1(x)\n",
    "        h2 = self.dropout(h1)\n",
    "        return self.w_2(h2)\n",
    "\n"
   ],
   "id": "6caa3bce86971792",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ADD & Norm Layers",
   "id": "752119740183a973"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:44:28.136632Z",
     "start_time": "2025-07-05T09:44:28.130263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    def __init__(self, size, dropout):\n",
    "        super().__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        output = x + self.dropout(sublayer(self.norm(x)))\n",
    "        return output\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        x_zscore = (x - mean) / torch.sqrt(std ** 2 + self.eps)\n",
    "        output = self.a_2*x_zscore+self.b_2\n",
    "\n",
    "        return output"
   ],
   "id": "ffcb4e6a47fbccda",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Encoder Schema",
   "id": "1e639a597c469749"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:44:36.477061Z",
     "start_time": "2025-07-05T09:44:36.472981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [deepcopy(layer) for i in range(N)])\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "            output = self.norm(x)\n",
    "        return output\n",
    "\n",
    "\n"
   ],
   "id": "ea4d66288322e715",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Encoder Layers",
   "id": "d51ffa403c7748db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:46:26.894103Z",
     "start_time": "2025-07-05T09:46:26.888739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = nn.ModuleList([deepcopy(\n",
    "        SublayerConnection(size, dropout)) for i in range(2)])\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        output = self.sublayer[1](x, self.feed_forward)\n",
    "        return output"
   ],
   "id": "58b0c6316f96906d",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Decoder Schema",
   "id": "b5516ac8bbefb008"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:47:00.787093Z",
     "start_time": "2025-07-05T09:47:00.782065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "  class Decoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [deepcopy(layer) for i in range(N)])\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        output = self.norm(x)\n",
    "        return output"
   ],
   "id": "4025df7055087db",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Decoder Layers",
   "id": "6674ae37066d0606"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:47:05.359917Z",
     "start_time": "2025-07-05T09:47:05.354213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn, src_attn,\n",
    "                 feed_forward, dropout):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = nn.ModuleList([deepcopy(\n",
    "        SublayerConnection(size, dropout)) for i in range(3)])\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        x = self.sublayer[0](x, lambda x:\n",
    "                 self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x:\n",
    "                 self.src_attn(x, memory, memory, src_mask))\n",
    "        output = self.sublayer[2](x, self.feed_forward)\n",
    "        return output"
   ],
   "id": "dc8d7cd432f55208",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Genarator",
   "id": "b012568454f606a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:47:07.576191Z",
     "start_time": "2025-07-05T09:47:07.571440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.proj(x)\n",
    "        probs = nn.functional.log_softmax(out, dim=-1)\n",
    "        return probs"
   ],
   "id": "b6e68b9484f7866d",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Transformer Combining All",
   "id": "67930a0a0266e92d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:47:11.412078Z",
     "start_time": "2025-07-05T09:47:11.406445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder,\n",
    "                 src_embed, tgt_embed, generator):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt),\n",
    "                            memory, src_mask, tgt_mask)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        memory = self.encode(src, src_mask)\n",
    "        output = self.decode(memory, src_mask, tgt, tgt_mask)\n",
    "        return output"
   ],
   "id": "a75dc6f41ea419bc",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Final Model",
   "id": "5953e0a68782e936"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:47:23.106443Z",
     "start_time": "2025-07-05T09:47:23.101173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_model(src_vocab, tgt_vocab, N, d_model,\n",
    "                 d_ff, h, dropout=0.1):\n",
    "    attn=MultiHeadedAttention(h, d_model).to(device)\n",
    "\n",
    "    ff=PositionwiseFeedForward(d_model, d_ff, dropout).to(device)\n",
    "\n",
    "    pos=PositionalEncoding(d_model, dropout).to(device )\n",
    "\n",
    "    model = Transformer(\n",
    "        Encoder(EncoderLayer(d_model,deepcopy(attn),deepcopy(ff),\n",
    "                             dropout).to(device),N).to(device),\n",
    "        Decoder(DecoderLayer(d_model,deepcopy(attn),\n",
    "             deepcopy(attn),deepcopy(ff), dropout).to(device),\n",
    "                N).to(device),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab).to(device),\n",
    "                      deepcopy(pos)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab).to(device),\n",
    "                      deepcopy(pos)),\n",
    "        Generator(d_model, tgt_vocab)).to(device)\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model.to(device)"
   ],
   "id": "3ea173808beb27fd",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:47:27.216349Z",
     "start_time": "2025-07-05T09:47:27.041456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = create_model(src_vocab, trg_vocab, N=6,\n",
    "    d_model=256, d_ff=1024, h=8, dropout=0.1)"
   ],
   "id": "a13bc86cd94faca1",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Loss Functions",
   "id": "ce28d2f8047570d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LOSS & OPTIMIZER",
   "id": "7f58247db6506ffe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:47:29.083743Z",
     "start_time": "2025-07-05T09:47:29.076676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super().__init__()\n",
    "        self.criterion = nn.KLDivLoss(reduction='sum')\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1,\n",
    "               target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        output = self.criterion(x, true_dist.detach())\n",
    "        return output"
   ],
   "id": "f65254ee1a5933b6",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:47:31.187175Z",
     "start_time": "2025-07-05T09:47:31.181809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NoamOpt:\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "\n",
    "    def step(self):\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def rate(self, step=None):\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        output = self.factor * (self.model_size ** (-0.5) *\n",
    "        min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "        return output"
   ],
   "id": "8149ccc21c195bd",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:47:34.579410Z",
     "start_time": "2025-07-05T09:47:34.573502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleLossCompute:\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "\n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n",
    "                              y.contiguous().view(-1)) / norm\n",
    "        loss.backward()\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "        return loss.data.item() * norm.float()"
   ],
   "id": "1ef43f158d4c5e15",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:47:41.004284Z",
     "start_time": "2025-07-05T09:47:39.022192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = NoamOpt(256, 1, 2000, torch.optim.Adam(\n",
    "    model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "criterion = LabelSmoothing(trg_vocab,\n",
    "                           padding_idx=0, smoothing=0.0)\n",
    "loss_func = SimpleLossCompute(\n",
    "            model.generator, criterion, optimizer)"
   ],
   "id": "1fa4dc7ab9f405dc",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:50:28.331357Z",
     "start_time": "2025-07-05T09:50:27.972993Z"
    }
   },
   "cell_type": "code",
   "source": "model.load_state_dict(torch.load(\"files/de2en.pth\"))",
   "id": "f78c43312dc4a1dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The training Process",
   "id": "ced86730473e1238"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T22:14:38.485294Z",
     "start_time": "2025-07-04T21:19:26.167945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    tloss=0\n",
    "    tokens=0\n",
    "    for batch in batches:\n",
    "        out = model(batch.src, batch.trg,\n",
    "                    batch.src_mask, batch.trg_mask)\n",
    "        loss = loss_func(out, batch.trg_y, batch.ntokens)\n",
    "        tloss += loss\n",
    "        tokens += batch.ntokens\n",
    "    print(f\"Epoch {epoch}, average loss: {tloss/tokens}\")\n",
    "torch.save(model.state_dict(),\"files/de2en.pth\")"
   ],
   "id": "b1be7205e8d7f937",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, average loss: 7.292831897735596\n",
      "Epoch 1, average loss: 4.555441856384277\n",
      "Epoch 2, average loss: 3.8222193717956543\n",
      "Epoch 3, average loss: 3.1755287647247314\n",
      "Epoch 4, average loss: 2.642914056777954\n",
      "Epoch 5, average loss: 2.3091909885406494\n",
      "Epoch 6, average loss: 2.0936484336853027\n",
      "Epoch 7, average loss: 1.92238450050354\n",
      "Epoch 8, average loss: 1.78951895236969\n",
      "Epoch 9, average loss: 1.6443781852722168\n",
      "Epoch 10, average loss: 1.494490623474121\n",
      "Epoch 11, average loss: 1.363502025604248\n",
      "Epoch 12, average loss: 1.2579774856567383\n",
      "Epoch 13, average loss: 1.1630743741989136\n",
      "Epoch 14, average loss: 1.081270694732666\n",
      "Epoch 15, average loss: 1.0096262693405151\n",
      "Epoch 16, average loss: 0.9453006982803345\n",
      "Epoch 17, average loss: 0.8964048624038696\n",
      "Epoch 18, average loss: 0.8463780283927917\n",
      "Epoch 19, average loss: 0.8027791380882263\n",
      "Epoch 20, average loss: 0.7681121230125427\n",
      "Epoch 21, average loss: 0.7279702425003052\n",
      "Epoch 22, average loss: 0.6965804696083069\n",
      "Epoch 23, average loss: 0.6639736294746399\n",
      "Epoch 24, average loss: 0.6383205056190491\n",
      "Epoch 25, average loss: 0.6119266152381897\n",
      "Epoch 26, average loss: 0.5870407223701477\n",
      "Epoch 27, average loss: 0.5639078617095947\n",
      "Epoch 28, average loss: 0.5392611026763916\n",
      "Epoch 29, average loss: 0.5176052451133728\n",
      "Epoch 30, average loss: 0.4974237382411957\n",
      "Epoch 31, average loss: 0.47531190514564514\n",
      "Epoch 32, average loss: 0.459255188703537\n",
      "Epoch 33, average loss: 0.4438632130622864\n",
      "Epoch 34, average loss: 0.4259956181049347\n",
      "Epoch 35, average loss: 0.4116884469985962\n",
      "Epoch 36, average loss: 0.39887169003486633\n",
      "Epoch 37, average loss: 0.385036826133728\n",
      "Epoch 38, average loss: 0.37125247716903687\n",
      "Epoch 39, average loss: 0.3613654673099518\n",
      "Epoch 40, average loss: 0.34735551476478577\n",
      "Epoch 41, average loss: 0.3379703164100647\n",
      "Epoch 42, average loss: 0.3266727030277252\n",
      "Epoch 43, average loss: 0.31840354204177856\n",
      "Epoch 44, average loss: 0.308244913816452\n",
      "Epoch 45, average loss: 0.2986917793750763\n",
      "Epoch 46, average loss: 0.2911073565483093\n",
      "Epoch 47, average loss: 0.28484389185905457\n",
      "Epoch 48, average loss: 0.27563557028770447\n",
      "Epoch 49, average loss: 0.2680332362651825\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "905a57a995d008e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:50:36.696326Z",
     "start_time": "2025-07-05T09:50:36.690338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def de2en(ger):\n",
    "    tokenized_ger= [tok.text for tok in de_token.tokenizer(ger)]\n",
    "    tokenized_ger=[\"BOS\"]+tokenized_ger+[\"EOS\"]\n",
    "    geridx=[de_word_dict.get(i,UNK) for i in tokenized_ger]\n",
    "    src=torch.tensor(geridx).long().to(device).unsqueeze(0)\n",
    "    src_mask=(src!=0).unsqueeze(-2)\n",
    "    memory=model.encode(src,src_mask)    #A\n",
    "    start_symbol=en_word_dict[\"BOS\"]\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    translation=[]\n",
    "    for i in range(100):\n",
    "        out = model.decode(memory,src_mask,ys,\n",
    "        subsequent_mask(ys.size(1)).type_as(src.data))\n",
    "        prob = model.generator(out[:, -1])    #B\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(\n",
    "            src.data).fill_(next_word)], dim=1)\n",
    "        sym = en_idx_dict[ys[0, -1].item()]\n",
    "        if sym != 'EOS':    #C\n",
    "            translation.append(sym)\n",
    "        else:\n",
    "            break\n",
    "    trans=\" \".join(translation)\n",
    "    for x in '''?:;.,'(\"-!&)%''':\n",
    "        trans=trans.replace(f\" {x}\",f\"{x}\")    #D\n",
    "    return trans"
   ],
   "id": "a5890583c43a6f19",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T10:04:43.739139Z",
     "start_time": "2025-07-05T10:04:43.733873Z"
    }
   },
   "cell_type": "code",
   "source": "trainde[2900]",
   "id": "3e7078b77454a1e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eine Person blickt aus dem Fenster auf einen Bus der Linie A.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T10:11:21.525618Z",
     "start_time": "2025-07-05T10:11:21.389971Z"
    }
   },
   "cell_type": "code",
   "source": "de2en(\"Ich gehe jetzt nach Hause \")",
   "id": "7d3911aff5e321a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am going home.'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T10:04:32.405137Z",
     "start_time": "2025-07-05T10:04:32.400487Z"
    }
   },
   "cell_type": "code",
   "source": "trainen[2900]",
   "id": "be68b5d6be96381e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A person looks out of the window on the A bus.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:51:57.726110Z",
     "start_time": "2025-07-05T09:51:57.720815Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "122b9696efee38c4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29001"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
